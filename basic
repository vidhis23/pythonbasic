def camel_to_snake(fields):
    snake_case_fields = []
    for field in fields:
        snake_case_field = field[0].lower() + ''.join(['_' + char.lower() if char.isupper() else char for char in field[1:]])
        snake_case_fields.append(snake_case_field)
    return snake_case_fields

fields = ["FirstName", "LastName", "Age"]
snake_case_fields = camel_to_snake(fields)
print(snake_case_fields)


def generate_file(list1, list2, filename):
    with open(filename, 'w') as file:
        for index, (item1, item2) in enumerate(zip(list1, list2)):
            file.write(f"('pqr', '{item1}', {index}, {index+1}, '{item2}')\n")

# Example lists
list1 = ['sm1fff', 'sm2', 'sm3']
list2 = ['so', 'so1', 'so2']
filename = 'output.txt'

# Generate file
generate_file(list1, list2, filename)



def adjust_spacing(input_file, output_file):
    with open(input_file, 'r') as file:
        lines = file.readlines()

    # Split lines into columns
    columns = [list(map(str.strip, line.strip('()\n').split(','))) for line in lines]

    # Determine the maximum width for each column
    max_widths = [max(len(item) for item in column) for column in zip(*columns)]

    # Adjust spacing for each line using maximum widths
    adjusted_lines = []
    for column in columns:
        adjusted_parts = [part.ljust(max_width) for part, max_width in zip(column, max_widths)]
        adjusted_lines.append('(' + ', '.join(adjusted_parts) + ')\n')

    # Write adjusted lines to the output file
    with open(output_file, 'w') as file:
        file.writelines(adjusted_lines)

# Example usage
input_file = 'input.txt'
output_file = 'output.txt'
adjust_spacing(input_file, output_file)



def format_columns(input_list, output_file):
    with open(output_file, 'w') as file:
        for column in input_list:
            formatted_column = f"{column} varchar(240) null\n"
            file.write(formatted_column)

# Example usage
input_list = ['id', 'name']
output_file = 'formatted_columns.txt'
format_columns(input_list, output_file)




import java.text.SimpleDateFormat;
import java.util.Calendar;
import java.util.Date;

public class Main {
    public static void main(String[] args) {
        String dateString = "2024-03-21"; // Your date string
        SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd");
        try {
            Date date = sdf.parse(dateString);
            Calendar calendar = Calendar.getInstance();
            calendar.setTime(date);
            int dayOfWeek = calendar.get(Calendar.DAY_OF_WEEK);
            // Calendar.DAY_OF_WEEK returns values from 1 (Sunday) to 7 (Saturday)
            String[] daysOfWeek = {"Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"};
            String dayOfWeekString = daysOfWeek[dayOfWeek - 1];
            System.out.println("Day of the week for " + dateString + " is: " + dayOfWeekString);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}


















$filePath = "largefile.csv"
$outputPath = "output"

Get-Content -Path $filePath -TotalCount 1000 | Out-File "$outputPath\first_1000_lines.csv" -Encoding utf8






MERGE INTO table_A AS target
USING other_table AS source
ON target.isin = source.isin OR target.cusip = source.cusip
WHEN MATCHED THEN
  UPDATE SET target.additional_column = source.additional_column
WHEN NOT MATCHED THEN
  INSERT (isin, cusip, additional_column) VALUES (source.isin, source.cusip, source.additional_column);




SELECT
    request_session_id AS SessionID,
    DB_NAME(resource_database_id) AS DatabaseName,
    OBJECT_NAME(resource_associated_entity_id) AS LockedObjectName,
    request_mode AS LockType,
    request_status AS Status
FROM
    sys.dm_tran_locks
WHERE
    resource_type = 'OBJECT'
    AND resource_database_id = DB_ID('YourDatabaseName')
    AND resource_associated_entity_id = OBJECT_ID('YourTableName');


UPDATE a
SET
    parentName = CASE
                    WHEN b.parentName IS NOT NULL AND b.parentName <> '' THEN b.parentName
                    -- ELSE a.parentName -- Removed ELSE clause
                 END,
    scName = CASE
                WHEN b.scName IS NOT NULL AND b.scName <> '' THEN b.scName
                -- ELSE a.scName -- Removed ELSE clause
             END
FROM
    TableA a
    JOIN TableB b ON a.id = b.id;


UPDATE A
SET A.SomeColumn = B.SomeColumn
FROM TableA A
JOIN (
    SELECT ID, SomeColumn, MAX(InsDate) AS LatestInsDate
    FROM TableB
    GROUP BY ID, SomeColumn
) AS B ON A.ID = B.ID;


UPDATE A
SET A.SomeColumn = B.SomeColumn
FROM TableA A
JOIN (
    SELECT ID, SomeColumn
    FROM (
        SELECT ID, SomeColumn,
               ROW_NUMBER() OVER (PARTITION BY ID ORDER BY InsDate DESC) AS rn
        FROM TableB
        WHERE InsDate >= DATEADD(DAY, -3, GETDATE()) -- Only consider rows from the past 3 days
    ) AS bLatest
    WHERE rn = 1
) AS B ON A.ID = B.ID;

# Define the two lists of strings
list1 = ["apple", "banana", "cherry", "date"]
list2 = ["banana", "date", "fig", "grape"]

# Find the common elements
common_elements = list(set(list1) & set(list2))

# Print the common elements
print("Common elements:", common_elements)


MERGE TableB AS Target
USING TableA AS Source
ON Target.ID = Source.ID
WHEN MATCHED THEN
    UPDATE SET
        Target.Name = Source.Name,
        Target.Value = Source.Value
WHEN NOT MATCHED BY TARGET THEN
    INSERT (ID, Name, Value)
    VALUES (Source.ID, Source.Name, Source.Value);


        for (Map.Entry<String, String> entry : map.entrySet()) {
            entries.add(new DataEntry(entry.getKey(), entry.getValue(), runId, filename, insertTime, insertDate));
        }

        for (DataEntry entry : entries) {
            namedParameterJdbcTemplate.update(sql, new BeanPropertySqlParameterSource(entry));
        }


        BiConsumer<String, String> consumer = (key, value) -> {
            try {
                entries.add(new DataEntry(key, value, runId, filename, insertTime, insertDate));
            } catch (Exception e) {
                // Handle exception
                System.err.println("Error creating DataEntry for entry with key: " + key + ", value: " + value);
                e.printStackTrace();
                // Optionally, you can throw or log the exception further
            }
        };

        // Loop through map entries and apply the consumer
        map.forEach(consumer);


CREATE VIEW UniqueEntries AS
WITH Combined AS (
    SELECT id, name,
        ROW_NUMBER() OVER (PARTITION BY id ORDER BY 
            CASE 
                WHEN name IS NOT NULL AND LTRIM(RTRIM(name)) != '' AND name != 'N.A.' THEN 1
                ELSE 2
            END
        ) AS rn
    FROM (
        SELECT id, name FROM a
        UNION ALL
        SELECT id, name FROM b
        UNION ALL
        SELECT id, name FROM c
    ) AS AllTables
)
SELECT id, name
FROM Combined
WHERE rn = 1;



CREATE VIEW UniqueEntries AS
WITH Combined AS (
    SELECT id, name, 
        ROW_NUMBER() OVER (PARTITION BY id ORDER BY 
            CASE 
                WHEN name IS NOT NULL AND LTRIM(RTRIM(name)) != '' AND name != 'N.A.' THEN 1
                ELSE 2
            END
        ) AS rn
    FROM (
        SELECT id, name FROM a
        UNION ALL
        SELECT id, name FROM b
        UNION ALL
        SELECT id, name FROM c
    ) AS AllTables
)
SELECT id, name
FROM Combined
WHERE rn = 1
OR id NOT IN (
    SELECT id
    FROM Combined
    WHERE rn = 1 AND name IS NOT NULL AND LTRIM(RTRIM(name)) != '' AND name != 'N.A.'
);



CREATE VIEW UniqueEntries AS
WITH Combined AS (
    SELECT id, name, 
        ROW_NUMBER() OVER (PARTITION BY id ORDER BY 
            CASE 
                WHEN name IS NOT NULL AND LTRIM(RTRIM(name)) != '' AND name != 'N.A.' THEN 1
                ELSE 2
            END
        ) AS rn
    FROM (
        SELECT id, name FROM a
        UNION ALL
        SELECT id, name FROM b
        UNION ALL
        SELECT id, name FROM c
    ) AS AllTables
),
Filtered AS (
    SELECT id, name
    FROM Combined
    WHERE rn = 1
),
Fallback AS (
    SELECT id, name
    FROM (
        SELECT id, name, ROW_NUMBER() OVER (PARTITION BY id ORDER BY rn) AS new_rn
        FROM Combined
    ) AS SubQuery
    WHERE new_rn = 2
)
SELECT id, name
FROM Filtered
UNION ALL
SELECT id, name
FROM Fallback
WHERE id NOT IN (SELECT id FROM Filtered);


ArgumentCaptor<ResultSetExtractor<Map<Integer, Long>>> captor = ArgumentCaptor.forClass(ResultSetExtractor.class);



import static org.mockito.Mockito.*;
import static org.junit.Assert.*;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.Map;
import org.junit.Test;
import org.mockito.ArgumentCaptor;
import org.springframework.jdbc.core.ResultSetExtractor;
import org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate;

public class YourTestClass {

    @Test
    public void testGetBatchSequence() throws SQLException {
        // Mocking NamedParameterJdbcTemplate
        NamedParameterJdbcTemplate mockNamedJdbcTemplate = mock(NamedParameterJdbcTemplate.class);

        // ArgumentCaptor to capture the ResultSetExtractor
        ArgumentCaptor<ResultSetExtractor> resultSetExtractorCaptor = ArgumentCaptor.forClass(ResultSetExtractor.class);

        // Setting up the behavior of mockNamedJdbcTemplate
        when(mockNamedJdbcTemplate.query(anyString(), resultSetExtractorCaptor.capture())).thenReturn(null);

        // Invoke the method to test, which uses mockNamedJdbcTemplate.query()
        // Example method call (you need to replace this with the actual method call):
        // yourService.getBatchSequence();

        // Now you have captured the ResultSetExtractor
        ResultSetExtractor<Map<Integer, Long>> resultSetExtractor = resultSetExtractorCaptor.getValue();

        // Mocking ResultSet
        ResultSet resultSet = mock(ResultSet.class);
        when(resultSet.next()).thenReturn(true, true, false); // returns true twice, then false
        when(resultSet.getLong("batchId")).thenReturn(1L);

        // Using the captured ResultSetExtractor to process the mock ResultSet
        Map<Integer, Long> result = resultSetExtractor.extractData(resultSet);

        // Assertions to verify the expected behavior
        // Example assertion (you need to replace this with the actual assertion):
        // assertEquals(expectedResult, result);
    }
}

        ArgumentCaptor<ResultSetExtractor> resultSetExtractorCaptor = ArgumentCaptor.forClass(ResultSetExtractor.class);

        // Setting up the behavior of mockNamedJdbcTemplate
        when(mockNamedJdbcTemplate.query(anyString(), resultSetExtractorCaptor.capture())).thenAnswer(invocation -> {
            ResultSetExtractor<Map<Integer, Long>> resultSetExtractor = resultSetExtractorCaptor.getValue();

            // Mocking ResultSet
            ResultSet resultSet = mock(ResultSet.class);
            when(resultSet.next()).thenReturn(true, true, false); // returns true twice, then false
            when(resultSet.getLong("batchId")).thenReturn(1L);

            // Using the captured ResultSetExtractor to process the mock ResultSet
            return resultSetExtractor.extractData(resultSet);
        });

 String path = "/path/to/file/";
        String fileName = "testFile.txt";
        File mockFile = PowerMockito.mock(File.class);

        PowerMockito.whenNew(File.class).withArguments(path + fileName).thenReturn(mockFile);
        PowerMockito.when(mockFile.exists()).thenReturn(true);




private Path tempDir;

    @BeforeEach
    void setUp() throws IOException {
        // Create a temporary directory for testing
        tempDir = Files.createTempDirectory("testDir");
    }

    @AfterEach
    void tearDown() throws IOException {
        // Delete the temporary directory after each test
        Files.walk(tempDir)
             .map(Path::toFile)
             .forEach(File::delete);
    }

    @Test
    void testProcessFile_FileExists() throws IOException {
        // Arrange
        String fileName = "testFile.txt";
        Path filePath = tempDir.resolve(fileName);
        Files.createFile(filePath); // Create a temporary file

        FileProcessor fileProcessor = new FileProcessor();

        // Act
        fileProcessor.processFile(tempDir.toString() + File.separator, fileName);

        // Assert
        assertTrue(Files.exists(filePath));
        System.out.println("File exists test executed.");
    }

1)Task assignments often occur on Mondays for completion within a two-day timeframe, aligning with our frequent releases. While I understand the need for agility, providing a lead time of 2-3 days prior to the start date would enable us to better grasp the task's requirements and address any initial questions. Having tasks or stories assigned 2-3 days prior to sprint planning would greatly help in understanding the upcoming work and preparing adequately.
2)Our frequent release schedule, while necessary, can sometimes impact productivity, particularly when significant time is needed for release-related tasks. Allocating ample time for these activities could help maintain productivity levels and ensure a smoother workflow.
3)I've noticed a lack of story grooming discussions, which could enhance our understanding of the tasks at hand and ensure better alignment with our project goals. Having a good number of story grooming sessions could significantly improve our preparedness and clarity on upcoming work.
4)Given our workload, which often includes four releases per sprint, the time allocated for individual tasks can be minimal. This tight schedule can affect testing and may impact our confidence in the work completed.
5)The absence of retrospective calls deprives us of an opportunity to voice concerns and offer suggestions for process improvement. Including these sessions could foster a more collaborative and constructive work environment.
6)Similarly, implementing pair programming could offer valuable insights and ensure a deeper understanding of the project for all team members. It's a practice that's widely recognized for its benefits in software development.
7)Allowing a day for Pull Request (PR) review could significantly improve the quality of our codebase and facilitate better collaboration among team members.
8)Occasionally, I encounter challenges during the evening when awaiting input. Having alternative tasks to work on during such instances could help mitigate delays and optimize time management.
9)I've noticed that Jira tickets are sometimes added after Change Request (CR) approval, leading to delays in task commencement. It would be beneficial to have tasks assigned prior to CR approval to streamline the workflow.
10)Lastly, I want to emphasize the importance of maintaining a positive and respectful tone, especially during team interactions. A more considerate approach could contribute to a healthier work environment and enhance team morale.
11)Thank you for considering these points. I believe addressing these issues could contribute to greater efficiency and effectiveness within our team.
12) Additionally, it would be helpful to know in advance which weekends are expected to have work so that I can plan my weekend accordingly. This foresight would allow for better personal time management and work-life balance.
